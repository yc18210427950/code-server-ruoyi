{
  "manifest": {
    "name": "minipass",
    "version": "5.0.0",
    "description": "minimal implementation of a PassThrough stream",
    "main": "./index.js",
    "module": "./index.mjs",
    "types": "./index.d.ts",
    "exports": {
      ".": {
        "import": {
          "types": "./index.d.ts",
          "default": "./index.mjs"
        },
        "require": {
          "types": "./index.d.ts",
          "default": "./index.js"
        }
      },
      "./package.json": "./package.json"
    },
    "devDependencies": {
      "@types/node": "^17.0.41",
      "end-of-stream": "^1.4.0",
      "node-abort-controller": "^3.1.1",
      "prettier": "^2.6.2",
      "tap": "^16.2.0",
      "through2": "^2.0.3",
      "ts-node": "^10.8.1",
      "typedoc": "^0.23.24",
      "typescript": "^4.7.3"
    },
    "scripts": {
      "pretest": "npm run prepare",
      "presnap": "npm run prepare",
      "prepare": "node ./scripts/transpile-to-esm.js",
      "snap": "tap",
      "test": "tap",
      "preversion": "npm test",
      "postversion": "npm publish",
      "postpublish": "git push origin --follow-tags",
      "typedoc": "typedoc ./index.d.ts",
      "format": "prettier --write . --loglevel warn"
    },
    "repository": {
      "type": "git",
      "url": "git+https://github.com/isaacs/minipass.git"
    },
    "keywords": [
      "passthrough",
      "stream"
    ],
    "author": {
      "name": "Isaac Z. Schlueter",
      "email": "i@izs.me",
      "url": "http://blog.izs.me/"
    },
    "license": "ISC",
    "files": [
      "index.d.ts",
      "index.js",
      "index.mjs"
    ],
    "tap": {
      "check-coverage": true
    },
    "engines": {
      "node": ">=8"
    },
    "prettier": {
      "semi": false,
      "printWidth": 80,
      "tabWidth": 2,
      "useTabs": false,
      "singleQuote": true,
      "jsxSingleQuote": false,
      "bracketSameLine": true,
      "arrowParens": "avoid",
      "endOfLine": "lf"
    },
    "_registry": "npm",
    "_loc": "/config/.cache/yarn/v6/npm-minipass-5.0.0-3e9788ffb90b694a5d0ec94479a45b5d8738133d-integrity/node_modules/minipass/package.json",
    "readmeFilename": "README.md",
    "readme": "# minipass\n\nA _very_ minimal implementation of a [PassThrough\nstream](https://nodejs.org/api/stream.html#stream_class_stream_passthrough)\n\n[It's very\nfast](https://docs.google.com/spreadsheets/d/1K_HR5oh3r80b8WVMWCPPjfuWXUgfkmhlX7FGI6JJ8tY/edit?usp=sharing)\nfor objects, strings, and buffers.\n\nSupports `pipe()`ing (including multi-`pipe()` and backpressure\ntransmission), buffering data until either a `data` event handler\nor `pipe()` is added (so you don't lose the first chunk), and\nmost other cases where PassThrough is a good idea.\n\nThere is a `read()` method, but it's much more efficient to\nconsume data from this stream via `'data'` events or by calling\n`pipe()` into some other stream. Calling `read()` requires the\nbuffer to be flattened in some cases, which requires copying\nmemory.\n\nIf you set `objectMode: true` in the options, then whatever is\nwritten will be emitted. Otherwise, it'll do a minimal amount of\nBuffer copying to ensure proper Streams semantics when `read(n)`\nis called.\n\n`objectMode` can also be set by doing `stream.objectMode = true`,\nor by writing any non-string/non-buffer data. `objectMode` cannot\nbe set to false once it is set.\n\nThis is not a `through` or `through2` stream. It doesn't\ntransform the data, it just passes it right through. If you want\nto transform the data, extend the class, and override the\n`write()` method. Once you're done transforming the data however\nyou want, call `super.write()` with the transform output.\n\nFor some examples of streams that extend Minipass in various\nways, check out:\n\n- [minizlib](http://npm.im/minizlib)\n- [fs-minipass](http://npm.im/fs-minipass)\n- [tar](http://npm.im/tar)\n- [minipass-collect](http://npm.im/minipass-collect)\n- [minipass-flush](http://npm.im/minipass-flush)\n- [minipass-pipeline](http://npm.im/minipass-pipeline)\n- [tap](http://npm.im/tap)\n- [tap-parser](http://npm.im/tap-parser)\n- [treport](http://npm.im/treport)\n- [minipass-fetch](http://npm.im/minipass-fetch)\n- [pacote](http://npm.im/pacote)\n- [make-fetch-happen](http://npm.im/make-fetch-happen)\n- [cacache](http://npm.im/cacache)\n- [ssri](http://npm.im/ssri)\n- [npm-registry-fetch](http://npm.im/npm-registry-fetch)\n- [minipass-json-stream](http://npm.im/minipass-json-stream)\n- [minipass-sized](http://npm.im/minipass-sized)\n\n## Differences from Node.js Streams\n\nThere are several things that make Minipass streams different\nfrom (and in some ways superior to) Node.js core streams.\n\nPlease read these caveats if you are familiar with node-core\nstreams and intend to use Minipass streams in your programs.\n\nYou can avoid most of these differences entirely (for a very\nsmall performance penalty) by setting `{async: true}` in the\nconstructor options.\n\n### Timing\n\nMinipass streams are designed to support synchronous use-cases.\nThus, data is emitted as soon as it is available, always. It is\nbuffered until read, but no longer. Another way to look at it is\nthat Minipass streams are exactly as synchronous as the logic\nthat writes into them.\n\nThis can be surprising if your code relies on\n`PassThrough.write()` always providing data on the next tick\nrather than the current one, or being able to call `resume()` and\nnot have the entire buffer disappear immediately.\n\nHowever, without this synchronicity guarantee, there would be no\nway for Minipass to achieve the speeds it does, or support the\nsynchronous use cases that it does. Simply put, waiting takes\ntime.\n\nThis non-deferring approach makes Minipass streams much easier to\nreason about, especially in the context of Promises and other\nflow-control mechanisms.\n\nExample:\n\n```js\n// hybrid module, either works\nimport { Minipass } from 'minipass'\n// or:\nconst { Minipass } = require('minipass')\n\nconst stream = new Minipass()\nstream.on('data', () => console.log('data event'))\nconsole.log('before write')\nstream.write('hello')\nconsole.log('after write')\n// output:\n// before write\n// data event\n// after write\n```\n\n### Exception: Async Opt-In\n\nIf you wish to have a Minipass stream with behavior that more\nclosely mimics Node.js core streams, you can set the stream in\nasync mode either by setting `async: true` in the constructor\noptions, or by setting `stream.async = true` later on.\n\n```js\n// hybrid module, either works\nimport { Minipass } from 'minipass'\n// or:\nconst { Minipass } = require('minipass')\n\nconst asyncStream = new Minipass({ async: true })\nasyncStream.on('data', () => console.log('data event'))\nconsole.log('before write')\nasyncStream.write('hello')\nconsole.log('after write')\n// output:\n// before write\n// after write\n// data event <-- this is deferred until the next tick\n```\n\nSwitching _out_ of async mode is unsafe, as it could cause data\ncorruption, and so is not enabled. Example:\n\n```js\nimport { Minipass } from 'minipass'\nconst stream = new Minipass({ encoding: 'utf8' })\nstream.on('data', chunk => console.log(chunk))\nstream.async = true\nconsole.log('before writes')\nstream.write('hello')\nsetStreamSyncAgainSomehow(stream) // <-- this doesn't actually exist!\nstream.write('world')\nconsole.log('after writes')\n// hypothetical output would be:\n// before writes\n// world\n// after writes\n// hello\n// NOT GOOD!\n```\n\nTo avoid this problem, once set into async mode, any attempt to\nmake the stream sync again will be ignored.\n\n```js\nconst { Minipass } = require('minipass')\nconst stream = new Minipass({ encoding: 'utf8' })\nstream.on('data', chunk => console.log(chunk))\nstream.async = true\nconsole.log('before writes')\nstream.write('hello')\nstream.async = false // <-- no-op, stream already async\nstream.write('world')\nconsole.log('after writes')\n// actual output:\n// before writes\n// after writes\n// hello\n// world\n```\n\n### No High/Low Water Marks\n\nNode.js core streams will optimistically fill up a buffer,\nreturning `true` on all writes until the limit is hit, even if\nthe data has nowhere to go. Then, they will not attempt to draw\nmore data in until the buffer size dips below a minimum value.\n\nMinipass streams are much simpler. The `write()` method will\nreturn `true` if the data has somewhere to go (which is to say,\ngiven the timing guarantees, that the data is already there by\nthe time `write()` returns).\n\nIf the data has nowhere to go, then `write()` returns false, and\nthe data sits in a buffer, to be drained out immediately as soon\nas anyone consumes it.\n\nSince nothing is ever buffered unnecessarily, there is much less\ncopying data, and less bookkeeping about buffer capacity levels.\n\n### Hazards of Buffering (or: Why Minipass Is So Fast)\n\nSince data written to a Minipass stream is immediately written\nall the way through the pipeline, and `write()` always returns\ntrue/false based on whether the data was fully flushed,\nbackpressure is communicated immediately to the upstream caller.\nThis minimizes buffering.\n\nConsider this case:\n\n```js\nconst { PassThrough } = require('stream')\nconst p1 = new PassThrough({ highWaterMark: 1024 })\nconst p2 = new PassThrough({ highWaterMark: 1024 })\nconst p3 = new PassThrough({ highWaterMark: 1024 })\nconst p4 = new PassThrough({ highWaterMark: 1024 })\n\np1.pipe(p2).pipe(p3).pipe(p4)\np4.on('data', () => console.log('made it through'))\n\n// this returns false and buffers, then writes to p2 on next tick (1)\n// p2 returns false and buffers, pausing p1, then writes to p3 on next tick (2)\n// p3 returns false and buffers, pausing p2, then writes to p4 on next tick (3)\n// p4 returns false and buffers, pausing p3, then emits 'data' and 'drain'\n// on next tick (4)\n// p3 sees p4's 'drain' event, and calls resume(), emitting 'resume' and\n// 'drain' on next tick (5)\n// p2 sees p3's 'drain', calls resume(), emits 'resume' and 'drain' on next tick (6)\n// p1 sees p2's 'drain', calls resume(), emits 'resume' and 'drain' on next\n// tick (7)\n\np1.write(Buffer.alloc(2048)) // returns false\n```\n\nAlong the way, the data was buffered and deferred at each stage,\nand multiple event deferrals happened, for an unblocked pipeline\nwhere it was perfectly safe to write all the way through!\n\nFurthermore, setting a `highWaterMark` of `1024` might lead\nsomeone reading the code to think an advisory maximum of 1KiB is\nbeing set for the pipeline. However, the actual advisory\nbuffering level is the _sum_ of `highWaterMark` values, since\neach one has its own bucket.\n\nConsider the Minipass case:\n\n```js\nconst m1 = new Minipass()\nconst m2 = new Minipass()\nconst m3 = new Minipass()\nconst m4 = new Minipass()\n\nm1.pipe(m2).pipe(m3).pipe(m4)\nm4.on('data', () => console.log('made it through'))\n\n// m1 is flowing, so it writes the data to m2 immediately\n// m2 is flowing, so it writes the data to m3 immediately\n// m3 is flowing, so it writes the data to m4 immediately\n// m4 is flowing, so it fires the 'data' event immediately, returns true\n// m4's write returned true, so m3 is still flowing, returns true\n// m3's write returned true, so m2 is still flowing, returns true\n// m2's write returned true, so m1 is still flowing, returns true\n// No event deferrals or buffering along the way!\n\nm1.write(Buffer.alloc(2048)) // returns true\n```\n\nIt is extremely unlikely that you _don't_ want to buffer any data\nwritten, or _ever_ buffer data that can be flushed all the way\nthrough. Neither node-core streams nor Minipass ever fail to\nbuffer written data, but node-core streams do a lot of\nunnecessary buffering and pausing.\n\nAs always, the faster implementation is the one that does less\nstuff and waits less time to do it.\n\n### Immediately emit `end` for empty streams (when not paused)\n\nIf a stream is not paused, and `end()` is called before writing\nany data into it, then it will emit `end` immediately.\n\nIf you have logic that occurs on the `end` event which you don't\nwant to potentially happen immediately (for example, closing file\ndescriptors, moving on to the next entry in an archive parse\nstream, etc.) then be sure to call `stream.pause()` on creation,\nand then `stream.resume()` once you are ready to respond to the\n`end` event.\n\nHowever, this is _usually_ not a problem because:\n\n### Emit `end` When Asked\n\nOne hazard of immediately emitting `'end'` is that you may not\nyet have had a chance to add a listener. In order to avoid this\nhazard, Minipass streams safely re-emit the `'end'` event if a\nnew listener is added after `'end'` has been emitted.\n\nIe, if you do `stream.on('end', someFunction)`, and the stream\nhas already emitted `end`, then it will call the handler right\naway. (You can think of this somewhat like attaching a new\n`.then(fn)` to a previously-resolved Promise.)\n\nTo prevent calling handlers multiple times who would not expect\nmultiple ends to occur, all listeners are removed from the\n`'end'` event whenever it is emitted.\n\n### Emit `error` When Asked\n\nThe most recent error object passed to the `'error'` event is\nstored on the stream. If a new `'error'` event handler is added,\nand an error was previously emitted, then the event handler will\nbe called immediately (or on `process.nextTick` in the case of\nasync streams).\n\nThis makes it much more difficult to end up trying to interact\nwith a broken stream, if the error handler is added after an\nerror was previously emitted.\n\n### Impact of \"immediate flow\" on Tee-streams\n\nA \"tee stream\" is a stream piping to multiple destinations:\n\n```js\nconst tee = new Minipass()\nt.pipe(dest1)\nt.pipe(dest2)\nt.write('foo') // goes to both destinations\n```\n\nSince Minipass streams _immediately_ process any pending data\nthrough the pipeline when a new pipe destination is added, this\ncan have surprising effects, especially when a stream comes in\nfrom some other function and may or may not have data in its\nbuffer.\n\n```js\n// WARNING! WILL LOSE DATA!\nconst src = new Minipass()\nsrc.write('foo')\nsrc.pipe(dest1) // 'foo' chunk flows to dest1 immediately, and is gone\nsrc.pipe(dest2) // gets nothing!\n```\n\nOne solution is to create a dedicated tee-stream junction that\npipes to both locations, and then pipe to _that_ instead.\n\n```js\n// Safe example: tee to both places\nconst src = new Minipass()\nsrc.write('foo')\nconst tee = new Minipass()\ntee.pipe(dest1)\ntee.pipe(dest2)\nsrc.pipe(tee) // tee gets 'foo', pipes to both locations\n```\n\nThe same caveat applies to `on('data')` event listeners. The\nfirst one added will _immediately_ receive all of the data,\nleaving nothing for the second:\n\n```js\n// WARNING! WILL LOSE DATA!\nconst src = new Minipass()\nsrc.write('foo')\nsrc.on('data', handler1) // receives 'foo' right away\nsrc.on('data', handler2) // nothing to see here!\n```\n\nUsing a dedicated tee-stream can be used in this case as well:\n\n```js\n// Safe example: tee to both data handlers\nconst src = new Minipass()\nsrc.write('foo')\nconst tee = new Minipass()\ntee.on('data', handler1)\ntee.on('data', handler2)\nsrc.pipe(tee)\n```\n\nAll of the hazards in this section are avoided by setting `{\nasync: true }` in the Minipass constructor, or by setting\n`stream.async = true` afterwards. Note that this does add some\noverhead, so should only be done in cases where you are willing\nto lose a bit of performance in order to avoid having to refactor\nprogram logic.\n\n## USAGE\n\nIt's a stream! Use it like a stream and it'll most likely do what\nyou want.\n\n```js\nimport { Minipass } from 'minipass'\nconst mp = new Minipass(options) // optional: { encoding, objectMode }\nmp.write('foo')\nmp.pipe(someOtherStream)\nmp.end('bar')\n```\n\n### OPTIONS\n\n- `encoding` How would you like the data coming _out_ of the\n  stream to be encoded? Accepts any values that can be passed to\n  `Buffer.toString()`.\n- `objectMode` Emit data exactly as it comes in. This will be\n  flipped on by default if you write() something other than a\n  string or Buffer at any point. Setting `objectMode: true` will\n  prevent setting any encoding value.\n- `async` Defaults to `false`. Set to `true` to defer data\n  emission until next tick. This reduces performance slightly,\n  but makes Minipass streams use timing behavior closer to Node\n  core streams. See [Timing](#timing) for more details.\n- `signal` An `AbortSignal` that will cause the stream to unhook\n  itself from everything and become as inert as possible. Note\n  that providing a `signal` parameter will make `'error'` events\n  no longer throw if they are unhandled, but they will still be\n  emitted to handlers if any are attached.\n\n### API\n\nImplements the user-facing portions of Node.js's `Readable` and\n`Writable` streams.\n\n### Methods\n\n- `write(chunk, [encoding], [callback])` - Put data in. (Note\n  that, in the base Minipass class, the same data will come out.)\n  Returns `false` if the stream will buffer the next write, or\n  true if it's still in \"flowing\" mode.\n- `end([chunk, [encoding]], [callback])` - Signal that you have\n  no more data to write. This will queue an `end` event to be\n  fired when all the data has been consumed.\n- `setEncoding(encoding)` - Set the encoding for data coming of\n  the stream. This can only be done once.\n- `pause()` - No more data for a while, please. This also\n  prevents `end` from being emitted for empty streams until the\n  stream is resumed.\n- `resume()` - Resume the stream. If there's data in the buffer,\n  it is all discarded. Any buffered events are immediately\n  emitted.\n- `pipe(dest)` - Send all output to the stream provided. When\n  data is emitted, it is immediately written to any and all pipe\n  destinations. (Or written on next tick in `async` mode.)\n- `unpipe(dest)` - Stop piping to the destination stream. This is\n  immediate, meaning that any asynchronously queued data will\n  _not_ make it to the destination when running in `async` mode.\n  - `options.end` - Boolean, end the destination stream when the\n    source stream ends. Default `true`.\n  - `options.proxyErrors` - Boolean, proxy `error` events from\n    the source stream to the destination stream. Note that errors\n    are _not_ proxied after the pipeline terminates, either due\n    to the source emitting `'end'` or manually unpiping with\n    `src.unpipe(dest)`. Default `false`.\n- `on(ev, fn)`, `emit(ev, fn)` - Minipass streams are\n  EventEmitters. Some events are given special treatment,\n  however. (See below under \"events\".)\n- `promise()` - Returns a Promise that resolves when the stream\n  emits `end`, or rejects if the stream emits `error`.\n- `collect()` - Return a Promise that resolves on `end` with an\n  array containing each chunk of data that was emitted, or\n  rejects if the stream emits `error`. Note that this consumes\n  the stream data.\n- `concat()` - Same as `collect()`, but concatenates the data\n  into a single Buffer object. Will reject the returned promise\n  if the stream is in objectMode, or if it goes into objectMode\n  by the end of the data.\n- `read(n)` - Consume `n` bytes of data out of the buffer. If `n`\n  is not provided, then consume all of it. If `n` bytes are not\n  available, then it returns null. **Note** consuming streams in\n  this way is less efficient, and can lead to unnecessary Buffer\n  copying.\n- `destroy([er])` - Destroy the stream. If an error is provided,\n  then an `'error'` event is emitted. If the stream has a\n  `close()` method, and has not emitted a `'close'` event yet,\n  then `stream.close()` will be called. Any Promises returned by\n  `.promise()`, `.collect()` or `.concat()` will be rejected.\n  After being destroyed, writing to the stream will emit an\n  error. No more data will be emitted if the stream is destroyed,\n  even if it was previously buffered.\n\n### Properties\n\n- `bufferLength` Read-only. Total number of bytes buffered, or in\n  the case of objectMode, the total number of objects.\n- `encoding` The encoding that has been set. (Setting this is\n  equivalent to calling `setEncoding(enc)` and has the same\n  prohibition against setting multiple times.)\n- `flowing` Read-only. Boolean indicating whether a chunk written\n  to the stream will be immediately emitted.\n- `emittedEnd` Read-only. Boolean indicating whether the end-ish\n  events (ie, `end`, `prefinish`, `finish`) have been emitted.\n  Note that listening on any end-ish event will immediateyl\n  re-emit it if it has already been emitted.\n- `writable` Whether the stream is writable. Default `true`. Set\n  to `false` when `end()`\n- `readable` Whether the stream is readable. Default `true`.\n- `pipes` An array of Pipe objects referencing streams that this\n  stream is piping into.\n- `destroyed` A getter that indicates whether the stream was\n  destroyed.\n- `paused` True if the stream has been explicitly paused,\n  otherwise false.\n- `objectMode` Indicates whether the stream is in `objectMode`.\n  Once set to `true`, it cannot be set to `false`.\n- `aborted` Readonly property set when the `AbortSignal`\n  dispatches an `abort` event.\n\n### Events\n\n- `data` Emitted when there's data to read. Argument is the data\n  to read. This is never emitted while not flowing. If a listener\n  is attached, that will resume the stream.\n- `end` Emitted when there's no more data to read. This will be\n  emitted immediately for empty streams when `end()` is called.\n  If a listener is attached, and `end` was already emitted, then\n  it will be emitted again. All listeners are removed when `end`\n  is emitted.\n- `prefinish` An end-ish event that follows the same logic as\n  `end` and is emitted in the same conditions where `end` is\n  emitted. Emitted after `'end'`.\n- `finish` An end-ish event that follows the same logic as `end`\n  and is emitted in the same conditions where `end` is emitted.\n  Emitted after `'prefinish'`.\n- `close` An indication that an underlying resource has been\n  released. Minipass does not emit this event, but will defer it\n  until after `end` has been emitted, since it throws off some\n  stream libraries otherwise.\n- `drain` Emitted when the internal buffer empties, and it is\n  again suitable to `write()` into the stream.\n- `readable` Emitted when data is buffered and ready to be read\n  by a consumer.\n- `resume` Emitted when stream changes state from buffering to\n  flowing mode. (Ie, when `resume` is called, `pipe` is called,\n  or a `data` event listener is added.)\n\n### Static Methods\n\n- `Minipass.isStream(stream)` Returns `true` if the argument is a\n  stream, and false otherwise. To be considered a stream, the\n  object must be either an instance of Minipass, or an\n  EventEmitter that has either a `pipe()` method, or both\n  `write()` and `end()` methods. (Pretty much any stream in\n  node-land will return `true` for this.)\n\n## EXAMPLES\n\nHere are some examples of things you can do with Minipass\nstreams.\n\n### simple \"are you done yet\" promise\n\n```js\nmp.promise().then(\n  () => {\n    // stream is finished\n  },\n  er => {\n    // stream emitted an error\n  }\n)\n```\n\n### collecting\n\n```js\nmp.collect().then(all => {\n  // all is an array of all the data emitted\n  // encoding is supported in this case, so\n  // so the result will be a collection of strings if\n  // an encoding is specified, or buffers/objects if not.\n  //\n  // In an async function, you may do\n  // const data = await stream.collect()\n})\n```\n\n### collecting into a single blob\n\nThis is a bit slower because it concatenates the data into one\nchunk for you, but if you're going to do it yourself anyway, it's\nconvenient this way:\n\n```js\nmp.concat().then(onebigchunk => {\n  // onebigchunk is a string if the stream\n  // had an encoding set, or a buffer otherwise.\n})\n```\n\n### iteration\n\nYou can iterate over streams synchronously or asynchronously in\nplatforms that support it.\n\nSynchronous iteration will end when the currently available data\nis consumed, even if the `end` event has not been reached. In\nstring and buffer mode, the data is concatenated, so unless\nmultiple writes are occurring in the same tick as the `read()`,\nsync iteration loops will generally only have a single iteration.\n\nTo consume chunks in this way exactly as they have been written,\nwith no flattening, create the stream with the `{ objectMode:\ntrue }` option.\n\n```js\nconst mp = new Minipass({ objectMode: true })\nmp.write('a')\nmp.write('b')\nfor (let letter of mp) {\n  console.log(letter) // a, b\n}\nmp.write('c')\nmp.write('d')\nfor (let letter of mp) {\n  console.log(letter) // c, d\n}\nmp.write('e')\nmp.end()\nfor (let letter of mp) {\n  console.log(letter) // e\n}\nfor (let letter of mp) {\n  console.log(letter) // nothing\n}\n```\n\nAsynchronous iteration will continue until the end event is reached,\nconsuming all of the data.\n\n```js\nconst mp = new Minipass({ encoding: 'utf8' })\n\n// some source of some data\nlet i = 5\nconst inter = setInterval(() => {\n  if (i-- > 0) mp.write(Buffer.from('foo\\n', 'utf8'))\n  else {\n    mp.end()\n    clearInterval(inter)\n  }\n}, 100)\n\n// consume the data with asynchronous iteration\nasync function consume() {\n  for await (let chunk of mp) {\n    console.log(chunk)\n  }\n  return 'ok'\n}\n\nconsume().then(res => console.log(res))\n// logs `foo\\n` 5 times, and then `ok`\n```\n\n### subclass that `console.log()`s everything written into it\n\n```js\nclass Logger extends Minipass {\n  write(chunk, encoding, callback) {\n    console.log('WRITE', chunk, encoding)\n    return super.write(chunk, encoding, callback)\n  }\n  end(chunk, encoding, callback) {\n    console.log('END', chunk, encoding)\n    return super.end(chunk, encoding, callback)\n  }\n}\n\nsomeSource.pipe(new Logger()).pipe(someDest)\n```\n\n### same thing, but using an inline anonymous class\n\n```js\n// js classes are fun\nsomeSource\n  .pipe(\n    new (class extends Minipass {\n      emit(ev, ...data) {\n        // let's also log events, because debugging some weird thing\n        console.log('EMIT', ev)\n        return super.emit(ev, ...data)\n      }\n      write(chunk, encoding, callback) {\n        console.log('WRITE', chunk, encoding)\n        return super.write(chunk, encoding, callback)\n      }\n      end(chunk, encoding, callback) {\n        console.log('END', chunk, encoding)\n        return super.end(chunk, encoding, callback)\n      }\n    })()\n  )\n  .pipe(someDest)\n```\n\n### subclass that defers 'end' for some reason\n\n```js\nclass SlowEnd extends Minipass {\n  emit(ev, ...args) {\n    if (ev === 'end') {\n      console.log('going to end, hold on a sec')\n      setTimeout(() => {\n        console.log('ok, ready to end now')\n        super.emit('end', ...args)\n      }, 100)\n    } else {\n      return super.emit(ev, ...args)\n    }\n  }\n}\n```\n\n### transform that creates newline-delimited JSON\n\n```js\nclass NDJSONEncode extends Minipass {\n  write(obj, cb) {\n    try {\n      // JSON.stringify can throw, emit an error on that\n      return super.write(JSON.stringify(obj) + '\\n', 'utf8', cb)\n    } catch (er) {\n      this.emit('error', er)\n    }\n  }\n  end(obj, cb) {\n    if (typeof obj === 'function') {\n      cb = obj\n      obj = undefined\n    }\n    if (obj !== undefined) {\n      this.write(obj)\n    }\n    return super.end(cb)\n  }\n}\n```\n\n### transform that parses newline-delimited JSON\n\n```js\nclass NDJSONDecode extends Minipass {\n  constructor (options) {\n    // always be in object mode, as far as Minipass is concerned\n    super({ objectMode: true })\n    this._jsonBuffer = ''\n  }\n  write (chunk, encoding, cb) {\n    if (typeof chunk === 'string' &&\n        typeof encoding === 'string' &&\n        encoding !== 'utf8') {\n      chunk = Buffer.from(chunk, encoding).toString()\n    } else if (Buffer.isBuffer(chunk)) {\n      chunk = chunk.toString()\n    }\n    if (typeof encoding === 'function') {\n      cb = encoding\n    }\n    const jsonData = (this._jsonBuffer + chunk).split('\\n')\n    this._jsonBuffer = jsonData.pop()\n    for (let i = 0; i < jsonData.length; i++) {\n      try {\n        // JSON.parse can throw, emit an error on that\n        super.write(JSON.parse(jsonData[i]))\n      } catch (er) {\n        this.emit('error', er)\n        continue\n      }\n    }\n    if (cb)\n      cb()\n  }\n}\n```\n",
    "licenseText": "The ISC License\n\nCopyright (c) 2017-2023 npm, Inc., Isaac Z. Schlueter, and Contributors\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\nIN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.npmmirror.com/minipass/-/minipass-5.0.0.tgz#3e9788ffb90b694a5d0ec94479a45b5d8738133d",
    "type": "tarball",
    "reference": "https://registry.npmmirror.com/minipass/-/minipass-5.0.0.tgz",
    "hash": "3e9788ffb90b694a5d0ec94479a45b5d8738133d",
    "integrity": "sha512-3FnjYuehv9k6ovOEbyOswadCDPX1piCfhV8ncmYtHOjuPwylVWsghTLo7rabjC3Rx5xD4HDx8Wm1xnMF7S5qFQ==",
    "registry": "npm",
    "packageName": "minipass",
    "cacheIntegrity": "sha512-3FnjYuehv9k6ovOEbyOswadCDPX1piCfhV8ncmYtHOjuPwylVWsghTLo7rabjC3Rx5xD4HDx8Wm1xnMF7S5qFQ== sha1-PpeI/7kLaUpdDslEeaRbXYc4Ez0="
  },
  "registry": "npm",
  "hash": "3e9788ffb90b694a5d0ec94479a45b5d8738133d"
}